
/*
Fused Multi-Head Attention Forward

This is an implementation of the Flash Attention algorithm
(see: Dao et al., https://arxiv.org/pdf/2205.14135v2.pdf)
*/

#include "SDP/fmha_forward.hpp"
#include "SDP/fmha_forward_kernel.hpp"

// clang-format off
// macros to be filled in CMake 
#define IMPL_T ${IMPL_T}
#define IMPL_ARCH_TAG gpu_arch::${IMPL_ARCH_TAG}
#define GPU_ARCH_${IMPL_ARCH_TAG}
#cmakedefine01 IMPL_KUSEALIBI
#cmakedefine01 IMPL_KUSEBIAS
#cmakedefine01 IMPL_KISCAUSAL
#cmakedefine01 IMPL_KSEQLAST
#cmakedefine01 IMPL_KISTRAINING
#cmakedefine01 IMPL_KISDROPOUT
// clang-format on

namespace gpu::xetla {

namespace fmha {
// The launcher of fmha forward kernel
template <
    typename fmha_policy,
    typename T,
    gpu_arch arch_tag,
    bool kUseAlibi,
    bool kUseBias,
    bool kIsCausal,
    bool kSeqLast,
    bool kIsTraining,
    bool kIsDropout>
cgfs_t xetla_fmha_forward_kernel(const dispatch_fmha_forward_args_t<T>& args) {
#ifdef SDP_DBG
  printf(
      "B, N, Nkv, F, T, H: %u, %u, %u, %u, %u, %u, UseAlibi: %d, UseBias: %d, IsCausal: %d, IsTraining: %d,"
      "IsDropout: %d, alibi @ 0x%llx, uAT %d, uMT %d, strideB %d, strideN %d, strideF %d, dropout_prob %f, kSeqLast %d\n",
      args.num_batches,
      args.num_heads,
      args.num_kv_heads,
      args.num_queries,
      args.num_keys,
      args.head_size,
      kUseAlibi,
      kUseBias,
      kIsCausal,
      kIsTraining,
      kIsDropout,
      (unsigned long long)args.alibi,
      args.alibi_padded_block_size,
      args.attn_mask_padded_block_size,
      args.bias_strideB,
      args.bias_strideN,
      args.bias_strideF,
      args.dropout_prob,
      kSeqLast);
#endif
  // fmha forward kernel
  using fmha_forward_op_t = fmha_forward_t<
      fmha_policy,
      T,
      arch_tag,
      kUseAlibi,
      kUseBias,
      kIsCausal,
      kSeqLast,
      kIsTraining,
      kIsDropout>;

  sycl::nd_range<3> NdRange = fmha_forward_op_t::get_nd_range(
      args.num_batches * args.num_heads, args.num_queries);

  FmhaForwardKernelFunctor<fmha_forward_op_t, T> kfn(args);
  return {[=](sycl::handler& cgh) { cgh.parallel_for(NdRange, kfn); }};
}

#define INSTANTIATE_POLICY(policy)           \
  template cgfs_t xetla_fmha_forward_kernel< \
      policy,                                \
      IMPL_T,                                \
      IMPL_ARCH_TAG,                         \
      IMPL_KUSEALIBI,                        \
      IMPL_KUSEBIAS,                         \
      IMPL_KISCAUSAL,                        \
      IMPL_KSEQLAST,                         \
      IMPL_KISTRAINING,                      \
      IMPL_KISDROPOUT>(const dispatch_fmha_forward_args_t<IMPL_T>& args)

#if (IMPL_KISTRAINING && IMPL_KISDROPOUT && defined(GPU_ARCH_XeHpc))
INSTANTIATE_POLICY(fmha_policy_64x64x64);
INSTANTIATE_POLICY(fmha_policy_128x128x128);
INSTANTIATE_POLICY(fmha_policy_128x128x256);
INSTANTIATE_POLICY(fmha_policy_64x128x512);
#endif

INSTANTIATE_POLICY(fmha_policy_8x128x64);
INSTANTIATE_POLICY(fmha_policy_64x128x64);

#if (!IMPL_KISDROPOUT && defined(GPU_ARCH_XeLpg))
INSTANTIATE_POLICY(stage0<fmha_policy_1x256x128>);
INSTANTIATE_POLICY(stage0<fmha_policy_1x512x128>);
#endif

INSTANTIATE_POLICY(fmha_policy_8x256x128);
INSTANTIATE_POLICY(fmha_policy_8x512x128);

#if defined(GPU_ARCH_XeLpg)
INSTANTIATE_POLICY(stage0<fmha_policy_32x128x128>);
#else
INSTANTIATE_POLICY(fmha_policy_64x128x128);
#endif

#if defined(GPU_ARCH_XeLpg)
#else
INSTANTIATE_POLICY(fmha_policy_8x256x256);
INSTANTIATE_POLICY(fmha_policy_64x128x256);
#if defined(GPU_ARCH_XeHpc)
INSTANTIATE_POLICY(fmha_policy_64x256x256);
#if !(IMPL_KISTRAINING && IMPL_KISDROPOUT)
INSTANTIATE_POLICY(fmha_policy_64x128x512);
#endif
#endif
#endif
} // namespace fmha
} // namespace gpu::xetla
